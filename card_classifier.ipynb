{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:31:37.342138Z",
     "start_time": "2024-10-28T10:31:35.424389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from tqdm import tqdm"
   ],
   "id": "b5fcb5e3388bfa15",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:31:37.345170Z",
     "start_time": "2024-10-28T10:31:37.343157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "fa2556da15bf1627",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-28T10:31:37.360325Z",
     "start_time": "2024-10-28T10:31:37.345170Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:21:56.379448Z",
     "start_time": "2024-10-28T11:21:56.375927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset_path = 'dataset/train'\n",
    "test_dataset_path = 'dataset/test'\n",
    "gop3_dataset_path = \"dataset/gop3_dataset\""
   ],
   "id": "16f4eabdc0139b6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:21:56.923414Z",
     "start_time": "2024-10-28T11:21:56.920881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 (or any size that fits the model)\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize based on ImageNet stats\n",
    "])"
   ],
   "id": "fac188d9c4034638",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:21:57.326615Z",
     "start_time": "2024-10-28T11:21:57.299831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_card_dataset = datasets.ImageFolder(root=train_dataset_path, transform=transform)\n",
    "test_card_dataset = datasets.ImageFolder(root=test_dataset_path, transform=transform)\n",
    "gop3_card_dataset = datasets.ImageFolder(root=gop3_dataset_path, transform=transform)"
   ],
   "id": "30f5247ae73e4443",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:26:15.097927Z",
     "start_time": "2024-10-28T11:26:15.094407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 48  # Set the batch size according to your GPU memory or system capacity\n",
    "train_card_dataloader = DataLoader(train_card_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_card_dataloader = DataLoader(test_card_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "gop3_card_dataloader = DataLoader(gop3_card_dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ],
   "id": "235b8cb9fc30326e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:26:16.887215Z",
     "start_time": "2024-10-28T11:26:16.884164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Class to Index Mapping:\")\n",
    "print(gop3_card_dataset.class_to_idx)"
   ],
   "id": "dfe87421075c5198",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to Index Mapping:\n",
      "{'2c': 0, '2d': 1, '2h': 2, '2s': 3, '3c': 4, '3d': 5, '3h': 6, '3s': 7, '4c': 8, '4d': 9, '4h': 10, '4s': 11, '5c': 12, '5d': 13, '5h': 14, '5s': 15, '6c': 16, '6d': 17, '6h': 18, '6s': 19, '7c': 20, '7d': 21, '7h': 22, '7s': 23, '8c': 24, '8d': 25, '8h': 26, '8s': 27, '9c': 28, '9d': 29, '9h': 30, '9s': 31, 'Ac': 32, 'Ad': 33, 'Ah': 34, 'As': 35, 'Jc': 36, 'Jd': 37, 'Jh': 38, 'Js': 39, 'Kc': 40, 'Kd': 41, 'Kh': 42, 'Ks': 43, 'Qc': 44, 'Qd': 45, 'Qh': 46, 'Qs': 47, 'Tc': 48, 'Td': 49, 'Th': 50, 'Ts': 51}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:31:37.402884Z",
     "start_time": "2024-10-28T10:31:37.398216Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_card_dataset.classes)",
   "id": "2f68e5f8ff463fff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T10:35:40.408311Z",
     "start_time": "2024-10-28T10:35:40.176335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the pretrained ResNet50 model\n",
    "model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Freeze all layers except the last fully connected layer\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Replace the final layer with a new layer with the appropriate number of output classes\n",
    "num_classes = len(train_card_dataset.classes)  # Number of classes (52 for a deck of cards, for example)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move model to the device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ],
   "id": "7106813b128e4697",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:27:53.614232Z",
     "start_time": "2024-10-28T11:27:53.610720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1)  # Only the parameters of the final layer"
   ],
   "id": "3b4500d404f16d09",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:28:20.278104Z",
     "start_time": "2024-10-28T11:27:54.118520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training parameters\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Iterate over batches\n",
    "    for images, labels in tqdm(gop3_card_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy metrics\n",
    "        running_loss += loss.item() * images.size(0)  # Sum loss for the batch\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    epoch_loss = running_loss / len(train_card_dataset)\n",
    "    epoch_accuracy = correct / total * 100\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # Save the model if it's the best accuracy achieved\n",
    "    if epoch_accuracy > best_accuracy:\n",
    "        best_accuracy = epoch_accuracy\n",
    "        torch.save(model.state_dict(), 'best_card_model.pth')\n",
    "        print(\"Model saved as best_card_model.pth\")\n"
   ],
   "id": "2736336cbdb641fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1899, Accuracy: 3.85%\n",
      "Model saved as best_card_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.6253, Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.9055, Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 1.0077, Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.2867, Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.3049, Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.3063, Accuracy: 3.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:   0%|          | 0/2 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Iterate over batches\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(gop3_card_dataloader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     14\u001B[0m     images, labels \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;66;03m# Zero the parameter gradients\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1327\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_data()\n\u001B[0;32m   1328\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1330\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1293\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1289\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[0;32m   1290\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[0;32m   1291\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1292\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m-> 1293\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_get_data()\n\u001B[0;32m   1294\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1295\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1119\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1128\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1131\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_queue\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1133\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1134\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\multiprocessing\\queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[0;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[1;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout):\n\u001B[0;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\multiprocessing\\connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[1;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\multiprocessing\\connection.py:346\u001B[0m, in \u001B[0;36mPipeConnection._poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_got_empty_message \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m    344\u001B[0m             _winapi\u001B[38;5;241m.\u001B[39mPeekNamedPipe(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle)[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 346\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(wait([\u001B[38;5;28mself\u001B[39m], timeout))\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\multiprocessing\\connection.py:896\u001B[0m, in \u001B[0;36mwait\u001B[1;34m(object_list, timeout)\u001B[0m\n\u001B[0;32m    893\u001B[0m                 ready_objects\u001B[38;5;241m.\u001B[39madd(o)\n\u001B[0;32m    894\u001B[0m                 timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 896\u001B[0m     ready_handles \u001B[38;5;241m=\u001B[39m _exhaustive_wait(waithandle_to_obj\u001B[38;5;241m.\u001B[39mkeys(), timeout)\n\u001B[0;32m    897\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    898\u001B[0m     \u001B[38;5;66;03m# request that overlapped reads stop\u001B[39;00m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ov \u001B[38;5;129;01min\u001B[39;00m ov_list:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\faculty-nlp\\Lib\\multiprocessing\\connection.py:828\u001B[0m, in \u001B[0;36m_exhaustive_wait\u001B[1;34m(handles, timeout)\u001B[0m\n\u001B[0;32m    826\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    827\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m L:\n\u001B[1;32m--> 828\u001B[0m     res \u001B[38;5;241m=\u001B[39m _winapi\u001B[38;5;241m.\u001B[39mWaitForMultipleObjects(L, \u001B[38;5;28;01mFalse\u001B[39;00m, timeout)\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;241m==\u001B[39m WAIT_TIMEOUT:\n\u001B[0;32m    830\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:26:26.603344Z",
     "start_time": "2024-10-28T11:26:23.077850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import torch\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_card_model.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize lists to store true and predicted labels\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(gop3_card_dataloader, desc=\"Test\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Store labels and predictions for metrics calculation\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for each class\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=range(num_classes))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Print overall accuracy\n",
    "print(f\"Overall Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# Print precision, recall, and F1 score for each class\n",
    "print(\"Class-wise Precision, Recall, and F1 Score:\")\n",
    "for idx, class_name in enumerate(train_card_dataset.classes):\n",
    "    print(f\"{class_name}: Precision: {precision[idx]:.2f}, Recall: {recall[idx]:.2f}, F1 Score: {f1_score[idx]:.2f}\")\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ],
   "id": "d4c128c138b7b2cf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 13.46%\n",
      "\n",
      "Class-wise Precision, Recall, and F1 Score:\n",
      "2c: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "2d: Precision: 0.10, Recall: 1.00, F1 Score: 0.18\n",
      "2h: Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
      "2s: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "3c: Precision: 0.50, Recall: 1.00, F1 Score: 0.67\n",
      "3d: Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
      "3h: Precision: 0.50, Recall: 1.00, F1 Score: 0.67\n",
      "3s: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "4c: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "4d: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "4h: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "4s: Precision: 0.25, Recall: 1.00, F1 Score: 0.40\n",
      "5c: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "5d: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "5h: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "5s: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "6c: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "6d: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "6h: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "6s: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "7c: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "7d: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "7h: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "7s: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "8c: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "8d: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "8h: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "8s: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "9c: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "9d: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "9h: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "9s: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Ac: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Ad: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Ah: Precision: 0.12, Recall: 1.00, F1 Score: 0.22\n",
      "As: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Jc: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Jd: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Jh: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Js: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Kc: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Kd: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Kh: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Ks: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Qc: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Qd: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Qh: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Qs: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Tc: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Td: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Th: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "Ts: Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc5816055048ca01"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
